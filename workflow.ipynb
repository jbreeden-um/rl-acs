{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf5d2db-5453-469c-9357-c37dedea7e89",
   "metadata": {},
   "source": [
    "# Sample Workflow for d3rlpy Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bfb6706a-eaec-4154-be04-e2b7c168479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "import subprocess\n",
    "import os\n",
    "import d3rlpy\n",
    "plt.style.use('matplotlibrc')\n",
    "\n",
    "from Python.data_sampler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d8a2f-129e-4b9c-81cd-55314fabeabd",
   "metadata": {},
   "source": [
    "## Building an MDPDataset\n",
    "\n",
    "We first read in a large batch of samples from the file. As `d3rlpy` wants it in the form (observations, actions, rewards, terminal flags), we go ahead and do that. Here's a helper function to get a dataset from a list of chunks of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3456d718-b8bb-460f-a429-9d99633145f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(chunks, batch_size=30000, \n",
    "                path=\"collected_data/rl_det_small.txt\"):\n",
    "    random.seed(0)\n",
    "    samples = DataSampler(path_to_data=path)\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    next_states = []\n",
    "    for chunk in chunks:\n",
    "        samples.use_chunk(chunk)\n",
    "        samples.read_chunk()\n",
    "        [statesChunk, actionsChunk, rewardsChunk, nextStatesChunk] = samples.get_batch(batch_size)\n",
    "        states.append(statesChunk)\n",
    "        actions.append(actionsChunk)\n",
    "        rewards.append(rewardsChunk)\n",
    "        next_states.append(nextStatesChunk)\n",
    "    states = torch.cat(states)\n",
    "    actions = torch.cat(actions)\n",
    "    rewards = torch.cat(rewards)\n",
    "    next_states = torch.cat(next_states)\n",
    "    terminals = np.zeros(len(states))\n",
    "    terminals[::100] = 1 #episode length 100, change if necessary\n",
    "    print(states.shape)\n",
    "    dataset = d3rlpy.dataset.MDPDataset(states.numpy(), \n",
    "                                        actions.numpy(), \n",
    "                                        rewards.numpy(), terminals)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaff27f-fd9a-4ad2-81c6-fca5f5fe6ce9",
   "metadata": {},
   "source": [
    "We can build the dataset from there, just like this, and split into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f543168b-2603-47ed-bff8-d0bafb40bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  7.95731469e+08 -8.17891077e-02 -1.19999531e-03\n",
      "  7.39998658e-03  0.00000000e+00 -5.33423489e+00 -1.57091618e+00\n",
      "  2.09713430e-01 -2.63658359e-01  6.00000000e-01]\n",
      "Read chunk # 4 out of 10000\n",
      "[ 0.00000000e+00  7.95731469e+08  1.24610892e-01  2.40000469e-03\n",
      " -7.60001342e-03  0.00000000e+00 -5.33423489e+00 -1.57091618e+00\n",
      " -2.20016566e-01  3.79282423e-01 -6.00000000e-01]\n",
      "Read chunk # 6 out of 10000\n",
      "[ 0.00000000e+00  7.95731469e+08 -9.01891077e-02  1.08000047e-02\n",
      "  3.99986580e-04  0.00000000e+00 -5.33423489e+00 -1.57091618e+00\n",
      " -3.17973088e-02 -2.40776052e-01  6.00000000e-01]\n",
      "Read chunk # 8 out of 10000\n",
      "[ 0.00000000e+00  7.95731469e+08  6.91108923e-02 -5.99999531e-03\n",
      " -6.00001342e-03  0.00000000e+00 -5.33423489e+00 -1.57091618e+00\n",
      " -1.42355434e-01  2.22081792e-01 -6.00000000e-01]\n",
      "Read chunk # 10 out of 10000\n",
      "torch.Size([111080, 6])\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset([3,5,7,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f051bee1-1f8b-4acc-a658-d80a5b4df54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_episodes, test_episodes = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1025ba17-f95f-426b-adc1-9312e5e180fa",
   "metadata": {},
   "source": [
    "## Setting up an Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5ef782b-6847-4fa4-8d95-3fa8904866bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d3rlpy.algos import CQL\n",
    "model = CQL(q_func_factory='qr',\n",
    "            use_gpu=False) #change it to true if you have one\n",
    "model.build_with_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2fd44e0e-0ab2-4ab0-8f96-7a8eb382cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.005670299844455813\n"
     ]
    }
   ],
   "source": [
    "from d3rlpy.metrics.scorer import td_error_scorer\n",
    "from d3rlpy.metrics.scorer import average_value_estimation_scorer\n",
    "from d3rlpy.metrics.scorer import initial_state_value_estimation_scorer\n",
    "\n",
    "# calculate metrics with test dataset\n",
    "ave_error_init = average_value_estimation_scorer(model, test_episodes)\n",
    "print(ave_error_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0384d5-a843-4d30-a355-404215f27fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_episodes,\n",
    "        eval_episodes=test_episodes,\n",
    "        n_epochs=5,\n",
    "        scorers={\n",
    "            'td_error': td_error_scorer,\n",
    "            'init_value': initial_state_value_estimation_scorer,\n",
    "            'ave_value': average_value_estimation_scorer\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb0460-f723-4b67-a553-57887d11dbc9",
   "metadata": {},
   "source": [
    "## Off-Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d639afd-476b-4844-9921-f001f81abf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  7.95731469e+08 -7.24891077e-02 -1.35999953e-02\n",
      " -4.20001342e-03  0.00000000e+00 -5.33423489e+00 -1.57091618e+00\n",
      " -6.23311010e-02 -1.64283998e-01  6.00000000e-01]\n",
      "Read chunk # 5 out of 10000\n",
      "[ 0.00000000e+00  7.95731469e+08  7.01089229e-03 -4.19999531e-03\n",
      "  7.39998658e-03  0.00000000e+00 -5.33423489e+00 -1.57091618e+00\n",
      "  2.21623335e-01 -2.86362315e-02 -8.00043364e-02]\n",
      "Read chunk # 7 out of 10000\n",
      "[ 0.00000000e+00  7.95731469e+08 -1.03989108e-01 -1.37999953e-02\n",
      "  7.99998658e-03  0.00000000e+00 -5.33423489e+00 -1.57091618e+00\n",
      "  2.76352555e-01 -3.26280816e-01  6.00000000e-01]\n",
      "Read chunk # 9 out of 10000\n",
      "[ 0.00000000e+00  7.95731469e+08  9.46108923e-02 -1.43999953e-02\n",
      " -1.50001342e-03  0.00000000e+00 -5.33423489e+00 -1.57091618e+00\n",
      "  1.56237335e-02  2.60569314e-01 -6.00000000e-01]\n",
      "Read chunk # 11 out of 10000\n",
      "torch.Size([111080, 6])\n",
      "2022-04-06 18:35.50 [debug    ] RandomIterator is selected.\n",
      "2022-04-06 18:35.50 [info     ] Directory is created at d3rlpy_logs/FQE_20220406183550\n",
      "2022-04-06 18:35.50 [debug    ] Building models...\n",
      "2022-04-06 18:35.50 [debug    ] Models have been built.\n",
      "2022-04-06 18:35.50 [info     ] Parameters are saved to d3rlpy_logs/FQE_20220406183550/params.json params={'action_scaler': None, 'batch_size': 100, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'gamma': 0.99, 'generated_maxlen': 100000, 'learning_rate': 0.0001, 'n_critics': 1, 'n_frames': 1, 'n_steps': 1, 'optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'q_func_factory': {'type': 'mean', 'params': {'bootstrap': False, 'share_encoder': False}}, 'real_ratio': 1.0, 'reward_scaler': None, 'scaler': None, 'target_update_interval': 100, 'use_gpu': None, 'algorithm': 'FQE', 'observation_shape': (6,), 'action_size': 3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2064f54138e04f8bbb0d1abf58af8b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-06 18:36.09 [info     ] FQE_20220406183550: epoch=1 step=10000 epoch=1 metrics={'time_sample_batch': 0.0002603496313095093, 'time_algorithm_update': 0.001567529821395874, 'loss': 0.012148606970629952, 'time_step': 0.0019286755800247191, 'init_value': -1.5798275470733643, 'ave_value': -1.5798906309479264, 'soft_opc': nan} step=10000\n",
      "2022-04-06 18:36.09 [info     ] Model parameters are saved to d3rlpy_logs/FQE_20220406183550/model_10000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {'time_sample_batch': 0.0002603496313095093,\n",
       "   'time_algorithm_update': 0.001567529821395874,\n",
       "   'loss': 0.012148606970629952,\n",
       "   'time_step': 0.0019286755800247191,\n",
       "   'init_value': -1.5798275470733643,\n",
       "   'ave_value': -1.5798906309479264,\n",
       "   'soft_opc': nan})]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from d3rlpy.ope import FQE\n",
    "# metrics to evaluate with\n",
    "from d3rlpy.metrics.scorer import soft_opc_scorer\n",
    "\n",
    "\n",
    "ope_dataset = get_dataset([4,6,8,10])\n",
    "ope_train_episodes, ope_test_episodes = train_test_split(ope_dataset, test_size=0.2)\n",
    "\n",
    "fqe = FQE(algo=model, use_gpu=False) #change this if you have one!\n",
    "fqe.fit(ope_train_episodes, eval_episodes=ope_test_episodes,\n",
    "        n_steps=10000,\n",
    "        scorers={\n",
    "           'init_value': initial_state_value_estimation_scorer,\n",
    "            'ave_value': average_value_estimation_scorer,\n",
    "           'soft_opc': soft_opc_scorer(return_threshold=600)\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
